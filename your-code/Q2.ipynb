{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to enhance the `get_bow_from_docs` function so that it will work with HTML webpages. In HTML, there are a lot of messy codes such as HTML tags, Javascripts, [unicodes](https://www.w3schools.com/charsets/ref_utf_misc_symbols.asp) that will mess up your bag of words. We need to clean up those junk before generating BoW.\n",
    "\n",
    "Next, what you will do is to define several new functions each of which is specialized to clean up the HTML codes in one aspect. For instance, you can have a `strip_html_tags` function to remove all HTML tags, a `remove_punctuation` function to remove all punctuation, a `to_lower_case` function to convert string to lowercase, and a `remove_unicode` function to remove all unicodes.\n",
    "\n",
    "Then in your `get_bow_from_doc` function, you will call each of those functions you created to clean up the HTML before you generate the corpus.\n",
    "\n",
    "Note: Please use Python string operations and regular expression only in this lab. Do not use extra libraries such as `beautifulsoup` because otherwise you loose the purpose of practicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your string handling functions below\n",
    "# Minimal 3 functions\n",
    "import re\n",
    "import string\n",
    "\n",
    "def strip_html_tags(docs):\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, '', docs)\n",
    "\n",
    "def remove_punctuation(docs):\n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    for x in docs.lower():\n",
    "        if x in punctuations:\n",
    "            docs = docs.replace(x, \"\")\n",
    "    print(docs)\n",
    "\n",
    "def to_lower_case(docs):\n",
    "    [i.lower() for i in docs]\n",
    "\n",
    "def remove_unicode(docs):\n",
    "    docs.encode('ascii', 'ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, paste your previously written `get_bow_from_docs` function below. Call your functions above at the appropriate place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bow_from_docs(docs, stop_words=[]):\n",
    "    # In the function, first define the variables you will use such as `corpus`, `bag_of_words`, and `term_freq`.\n",
    "    corpus = []\n",
    "    bag_of_words = []\n",
    "    term_freq = []\n",
    "    \n",
    "    # write your codes here\n",
    "    for i in docs:\n",
    "        with open(i,'r', encoding=\"utf-8\") as file:\n",
    "            docs = file.read()\n",
    "\n",
    "        docs = strip_html_tags(docs)\n",
    "        docs = remove_punctuation(docs)\n",
    "    \n",
    "    for line in corpus:\n",
    "        line = line.split()\n",
    "        for word in line:\n",
    "            if word not in (bag_of_words) and word not in (stop_words):\n",
    "                bag_of_words.append(word)\n",
    "    \n",
    "\n",
    "    for line in corpus:\n",
    "        line = line.split()\n",
    "        for word in bag_of_words:\n",
    "            term_freq.append(line.count(word))\n",
    "            \n",
    "    return {\n",
    "        \"bag_of_words\": bag_of_words,\n",
    "        \"term_freq\": term_freq\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, read the content from the three HTML webpages in the `your-codes` directory to test your function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Data analysis  Wikipedia\n",
      "\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\n",
      "Data analysis\t\t\t\n",
      "\t\t\t\tFrom Wikipedia the free encyclopedia\t\t\t\t\n",
      "\t\t\t\t\t\t\t\tJump to navigation\n",
      "\t\t\t\tJump to search\n",
      "\t\t\t\tPart of a series on StatisticsData visualization\n",
      "Major dimensions\n",
      "Exploratory data analysis160822632 Information design\n",
      "Interactive data visualization\n",
      "Descriptive statistics160822632 Inferential statistics\n",
      "Statistical graphics160822632 Plot\n",
      "Data analysis 160822632 Infographic\n",
      "Data science\n",
      "\n",
      "Important figures\n",
      "Tamara Munzner 160822632 Ben Shneiderman 160822632 John W Tukey 160822632 Edward Tufte 160822632 Fernanda Viégas 160822632 Hadley Wickham\n",
      "\n",
      "Information graphic types\n",
      "Line chart 160822632 Bar chart\n",
      "Histogram160822632 Scatterplot\n",
      "Boxplot160822632 Pareto chart\n",
      "Pie chart160822632 Area chart\n",
      "Control chart 160822632 Run chart\n",
      "Stemandleaf display160822632 Cartogram\n",
      "Small multiple160822632 Sparkline\n",
      "Table\n",
      "\n",
      "Related topics\n",
      "Data160822632Information\n",
      "Big data160822632 Database\n",
      "Chartjunk160822632 Visual perception\n",
      "Regression analysis160822632 Statistical model\n",
      "Misleading graph\n",
      "vte\n",
      "Computational physics\n",
      "Numerical analysis16018332Simulation\n",
      "\n",
      "Data analysis16018332Visualization\n",
      "\n",
      "PotentialsMorseLongrange potential16018332LennardJones potential16018332Yukawa potential16018332Morse potential\n",
      "\n",
      "Fluid dynamicsFinite difference16018332Finite volume\n",
      "Finite element16018332Boundary element \n",
      "Lattice Boltzmann16018332Riemann solver\n",
      "Dissipative particle dynamics\n",
      "Smoothed particle hydrodynamics\n",
      "\n",
      "Turbulence models\n",
      "\n",
      "Monte Carlo methodsIntegration16018332Gibbs sampling16018332Metropolis algorithm\n",
      "\n",
      "ParticleNbody16018332Particleincell\n",
      "Molecular dynamics\n",
      "\n",
      "ScientistsGodunov16018332Ulam16018332 von Neumann16018332Galerkin16018332 Lorenz16018332Wilson\n",
      "vte\n",
      "Data analysis is a process of inspecting cleansing transforming and modeling data with the goal of discovering useful information informing conclusions and supporting decisionmaking Data analysis has multiple facets and approaches encompassing diverse techniques under a variety of names while being used in different business science and social science domains\n",
      "Data mining is a particular data analysis technique that focuses on modeling and knowledge discovery for predictive rather than purely descriptive purposes while business intelligence covers data analysis that relies heavily on aggregation focusing mainly on business information91193 In statistical applications data analysis can be divided into descriptive statistics exploratory data analysis EDA and confirmatory data analysis CDA EDA focuses on discovering new features in the data while CDA focuses on confirming or falsifying existing hypotheses Predictive analytics focuses on application of statistical models for predictive forecasting or classification while text analytics applies statistical linguistic and structural techniques to extract and classify information from textual sources a species of unstructured data All of the above are varieties of data analysis\n",
      "Data integration is a precursor to data analysis91according to whom93 and data analysis is closely linked91how93 to data visualization and data dissemination The term data analysis is sometimes used as a synonym for data modeling\n",
      "\n",
      "Contents\n",
      "\n",
      "1 The process of data analysis\n",
      "\n",
      "11 Data requirements\n",
      "12 Data collection\n",
      "13 Data processing\n",
      "14 Data cleaning\n",
      "15 Exploratory data analysis\n",
      "16 Modeling and algorithms\n",
      "17 Data product\n",
      "18 Communication\n",
      "\n",
      "\n",
      "2 Quantitative messages\n",
      "3 Techniques for analyzing quantitative data\n",
      "4 Analytical activities of data users\n",
      "5 Barriers to effective analysis\n",
      "\n",
      "51 Confusing fact and opinion\n",
      "52 Cognitive biases\n",
      "53 Innumeracy\n",
      "\n",
      "\n",
      "6 Other topics\n",
      "\n",
      "61 Smart buildings\n",
      "62 Analytics and business intelligence\n",
      "63 Education\n",
      "\n",
      "\n",
      "7 Practitioner notes\n",
      "\n",
      "71 Initial data analysis\n",
      "\n",
      "711 Quality of data\n",
      "712 Quality of measurements\n",
      "713 Initial transformations\n",
      "714 Did the implementation of the study fulfill the intentions of the research design\n",
      "715 Characteristics of data sample\n",
      "716 Final stage of the initial data analysis\n",
      "717 Analysis\n",
      "718 Nonlinear analysis\n",
      "\n",
      "\n",
      "72 Main data analysis\n",
      "\n",
      "721 Exploratory and confirmatory approaches\n",
      "722 Stability of results\n",
      "723 Statistical methods\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "8 Free software for data analysis\n",
      "9 International data analysis contests\n",
      "10 See also\n",
      "11 References\n",
      "\n",
      "111 Citations\n",
      "112 Bibliography\n",
      "\n",
      "\n",
      "12 Further reading\n",
      "\n",
      "\n",
      "\n",
      "The process of data analysisedit\n",
      "  Data science process flowchart from Doing Data Science Cathy ONeil and Rachel Schutt 2013\n",
      "Analysis refers to breaking a whole into its separate components for individual examination Data analysis is a process for obtaining raw data and converting it into information useful for decisionmaking by users Data is collected and analyzed to answer questions test hypotheses or disprove theories91293\n",
      "Statistician John Tukey defined data analysis in 1961 as Procedures for analyzing data techniques for interpreting the results of such procedures ways of planning the gathering of data to make its analysis easier more precise or more accurate and all the machinery and results of mathematical statistics which apply to analyzing data91393\n",
      "There are several phases that can be distinguished described below The phases are iterative in that feedback from later phases may result in additional work in earlier phases91493\n",
      "\n",
      "Data requirementsedit\n",
      "The data is necessary as inputs to the analysis which is specified based upon the requirements of those directing the analysis or customers who will use the finished product of the analysis The general type of entity upon which the data will be collected is referred to as an experimental unit eg a person or population of people Specific variables regarding a population eg age and income may be specified and obtained  Data may be numerical or categorical ie a text label for numbers91493\n",
      "\n",
      "Data collectionedit\n",
      "Data is collected from a variety of sources The requirements may be communicated by analysts to custodians of the data such as information technology personnel within an organization The data may also be collected from sensors in the environment such as traffic cameras satellites recording devices etc It may also be obtained through interviews  downloads from online sources or reading documentation91493\n",
      "\n",
      "Data processingedit\n",
      "  The phases of the intelligence cycle used to convert raw information into actionable intelligence or knowledge are conceptually similar to the phases in data analysis\n",
      "Data initially obtained must be processed or organised for analysis For instance these may involve placing data into rows and columns in a table format ie structured data for further analysis such as within a spreadsheet or statistical software91493\n",
      "\n",
      "Data cleaningedit\n",
      "Once processed and organised the data may be incomplete contain duplicates or contain errors The need for data cleaning will arise from problems in the way that data is entered and stored Data cleaning is the process of preventing and correcting these errors Common tasks include record matching identifying inaccuracy of data overall quality of existing data91593 deduplication and column segmentation91693 Such data problems can also be identified through a variety of analytical techniques For example with financial information the totals for particular variables may be compared against separately published numbers believed to be reliable91793 Unusual amounts above or below predetermined thresholds may also be reviewed  There are several types of data cleaning that depend on the type of data such as phone numbers email addresses employers etc  Quantitative data methods for outlier detection can be used to get rid of likely incorrectly entered data Textual data spell checkers can be used to lessen the amount of mistyped words but it is harder to tell if the words themselves are correct91893\n",
      "\n",
      "Exploratory data analysisedit\n",
      "Once the data is cleaned it can be analyzed Analysts may apply a variety of techniques referred to as exploratory data analysis to begin understanding the messages contained in the data91993911093 The process of exploration may result in additional data cleaning or additional requests for data so these activities may be iterative in nature Descriptive statistics such as the average or median may be generated to help understand the data Data visualization may also be used to examine the data in graphical format to obtain additional insight regarding the messages within the data91493\n",
      "\n",
      "Modeling and algorithmsedit\n",
      "Mathematical formulas or models called algorithms may be applied to the data to identify relationships among the variables such as correlation or causation In general terms models may be developed to evaluate a particular variable in the data based on other variables in the data with some residual error depending on model accuracy ie Data = Model + Error91293\n",
      "Inferential statistics includes techniques to measure relationships between particular variables  For example regression analysis may be used to model whether a change in advertising independent variable X explains the variation in sales dependent variable Y In mathematical terms Y sales is a function of X advertising It may be described as Y = aX + b + error where the model is designed such that a and b minimize the error when the model predicts Y for a given range of values of X Analysts may attempt to build models that are descriptive of the data to simplify analysis and communicate results91293\n",
      "\n",
      "Data productedit\n",
      "A data product is a computer application that takes data inputs and generates outputs feeding them back into the environment It may be based on a model or algorithm An example is an application that analyzes data about customer purchasing history and recommends other purchases the customer might enjoy91493\n",
      "\n",
      "Communicationedit\n",
      "  Data visualization to understand the results of a data analysis911193\n",
      "Main article Data visualization\n",
      "Once the data is analyzed it may be reported in many formats to the users of the analysis to support their requirements The users may have feedback which results in additional analysis As such much of the analytical cycle is iterative91493\n",
      "When determining how to communicate the results the analyst may consider data visualization techniques to help clearly and efficiently communicate the message to the audience Data visualization uses information displays such as tables and charts to help communicate key messages contained in the data Tables are helpful to a user who might lookup specific numbers while charts eg bar charts or line charts may help explain the quantitative messages contained in the data\n",
      "\n",
      "Quantitative messagesedit\n",
      "Main article Data visualization\n",
      "  A time series illustrated with a line chart demonstrating trends in US federal spending and revenue over time\n",
      "  A scatterplot illustrating correlation between two variables inflation and unemployment measured at points in time\n",
      "Stephen Few described eight types of quantitative messages that users may attempt to understand or communicate from a set of data and the associated graphs used to help communicate the message Customers specifying requirements and analysts performing the data analysis may consider these messages during the course of the process\n",
      "\n",
      "Timeseries A single variable is captured over a period of time such as the unemployment rate over a 10year period A line chart may be used to demonstrate the trend\n",
      "Ranking Categorical subdivisions are ranked in ascending or descending order such as a ranking of sales performance the measure by sales persons the category with each sales person a categorical subdivision during a single period  A bar chart may be used to show the comparison across the sales persons\n",
      "Parttowhole Categorical subdivisions are measured as a ratio to the whole ie a percentage out of 100  A pie chart or bar chart can show the comparison of ratios such as the market share represented by competitors in a market\n",
      "Deviation Categorical subdivisions are compared against a reference such as a comparison of actual vs budget expenses for several departments of a business for a given time period  A bar chart can show comparison of the actual versus the reference amount\n",
      "Frequency distribution Shows the number of observations of a particular variable for given interval such as the number of years in which the stock market return is between intervals such as 0–10 11–20 etc A histogram a type of bar chart may be used for this analysis\n",
      "Correlation Comparison between observations represented by two variables XY to determine if they tend to move in the same or opposite directions For example plotting unemployment X and inflation Y for a sample of months A scatter plot is typically used for this message\n",
      "Nominal comparison Comparing categorical subdivisions in no particular order such as the sales volume by product code A bar chart may be used for this comparison\n",
      "Geographic or geospatial Comparison of a variable across a map or layout such as the unemployment rate by state or the number of persons on the various floors of a building A cartogram is a typical graphic used911293911393\n",
      "Techniques for analyzing quantitative dataedit\n",
      "See also Problem solving\n",
      "Author Jonathan Koomey has recommended a series of best practices for understanding quantitative data  These include\n",
      "\n",
      "Check raw data for anomalies prior to performing your analysis\n",
      "Reperform important calculations such as verifying columns of data that are formula driven\n",
      "Confirm main totals are the sum of subtotals\n",
      "Check relationships between numbers that should be related in a predictable way such as ratios over time\n",
      "Normalize numbers to make comparisons easier such as analyzing amounts per person or relative to GDP or as an index value relative to a base year\n",
      "Break problems into component parts by analyzing factors that led to the results such as DuPont analysis of return on equity91793\n",
      "For the variables under examination analysts typically obtain descriptive statistics for them such as the mean average median and standard deviation They may also analyze the distribution of the key variables to see how the individual values cluster around the mean\n",
      "\n",
      "  An illustration of the MECE principle used for data analysis The consultants at McKinsey and Company named a technique for breaking a quantitative problem down into its component parts called the MECE principle Each layer can be broken down into its components each of the subcomponents must be mutually exclusive of each other and collectively add up to the layer above them The relationship is referred to as Mutually Exclusive and Collectively Exhaustive or MECE  For example profit by definition can be broken down into total revenue and total cost In turn total revenue can be analyzed by its components such as revenue of divisions A B and C which are mutually exclusive of each other and should add to the total revenue collectively exhaustive\n",
      "Analysts may use robust statistical measurements to solve certain analytical problems Hypothesis testing is used when a particular hypothesis about the true state of affairs is made by the analyst and data is gathered to determine whether that state of affairs is true or false For example the hypothesis might be that Unemployment has no effect on inflation which relates to an economics concept called the Phillips Curve Hypothesis testing involves considering the likelihood of Type I and type II errors which relate to whether the data supports accepting or rejecting the hypothesis\n",
      "Regression analysis may be used when the analyst is trying to determine the extent to which independent variable X affects dependent variable Y eg To what extent do changes in the unemployment rate X affect the inflation rate Y This is an attempt to model or fit an equation line or curve to the data such that Y is a function of X\n",
      "Necessary condition analysis NCA may be used when the analyst is trying to determine the extent to which independent variable X allows variable Y eg To what extent is a certain unemployment rate X necessary for a certain inflation rate Y Whereas multiple regression analysis uses additive logic where each Xvariable can produce the outcome and the Xs can compensate for each other they are sufficient but not necessary necessary condition analysis NCA uses necessity logic where one or more Xvariables allow the outcome to exist but may not produce it they are necessary but not sufficient Each single necessary condition must be present and compensation is not possible\n",
      "\n",
      "Analytical activities of data usersedit\n",
      "Users may have particular data points of interest within a data set as opposed to general messaging outlined above Such lowlevel user analytic activities are presented in the following table The taxonomy can also be organized by three poles of activities retrieving values finding data points and arranging data points911493911593911693911793\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Task\n",
      "GeneralDescription\n",
      "Pro FormaAbstract\n",
      "Examples\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "Retrieve Value\n",
      "\n",
      "Given a set of specific cases find attributes of those cases\n",
      "\n",
      "What are the values of attributes X Y Z  in the data cases A B C \n",
      "\n",
      " What is the mileage per gallon of the Ford Mondeo\n",
      " How long is the movie Gone with the Wind\n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "\n",
      " Filter\n",
      "\n",
      "Given some concrete conditions on attribute values find data cases satisfying those conditions\n",
      "\n",
      "Which data cases satisfy conditions A B C\n",
      "\n",
      " What Kelloggs cereals have high fiber\n",
      " What comedies have won awards\n",
      " Which funds underperformed the SP500\n",
      "\n",
      "\n",
      "\n",
      "3\n",
      "\n",
      "Compute Derived Value\n",
      "\n",
      "Given a set of data cases compute an aggregate numeric representation of those data cases\n",
      "\n",
      "What is the value of aggregation function F over a given set S of data cases\n",
      "\n",
      " What is the average calorie content of Post cereals\n",
      " What is the gross income of all stores combined\n",
      " How many manufacturers of cars are there\n",
      "\n",
      "\n",
      "\n",
      "4\n",
      "\n",
      "Find Extremum\n",
      "\n",
      "Find data cases possessing an extreme value of an attribute over its range within the data set\n",
      "\n",
      "What are the topbottom N data cases with respect to attribute A\n",
      "\n",
      " What is the car with the highest MPG\n",
      " What directorfilm has won the most awards\n",
      " What Marvel Studios film has the most recent release date\n",
      "\n",
      "\n",
      "\n",
      "5\n",
      "\n",
      "Sort\n",
      "\n",
      "Given a set of data cases rank them according to some ordinal metric\n",
      "\n",
      "What is the sorted order of a set S of data cases according to their value of attribute A\n",
      "\n",
      " Order the cars by weight\n",
      " Rank the cereals by calories\n",
      "\n",
      "\n",
      "\n",
      "6\n",
      "\n",
      "Determine Range\n",
      "\n",
      "Given a set of data cases and an attribute of interest find the span of values within the set\n",
      "\n",
      "What is the range of values of attribute A in a set S of data cases\n",
      "\n",
      " What is the range of film lengths\n",
      " What is the range of car horsepowers\n",
      " What actresses are in the data set\n",
      "\n",
      "\n",
      "\n",
      "7\n",
      "\n",
      "Characterize Distribution\n",
      "\n",
      "Given a set of data cases and a quantitative attribute of interest characterize the distribution of that attribute’s values over the set\n",
      "\n",
      "What is the distribution of values of attribute A in a set S of data cases\n",
      "\n",
      " What is the distribution of carbohydrates in cereals\n",
      " What is the age distribution of shoppers\n",
      "\n",
      "\n",
      "\n",
      "8\n",
      "\n",
      "Find Anomalies\n",
      "\n",
      "Identify any anomalies within a given set of data cases with respect to a given relationship or expectation eg statistical outliers\n",
      "\n",
      "Which data cases in a set S of data cases have unexpectedexceptional values\n",
      "\n",
      " Are there exceptions to the relationship between horsepower and acceleration\n",
      " Are there any outliers in protein\n",
      "\n",
      "\n",
      "\n",
      "9\n",
      "\n",
      "Cluster\n",
      "\n",
      "Given a set of data cases find clusters of similar attribute values\n",
      "\n",
      "Which data cases in a set S of data cases are similar in value for attributes X Y Z \n",
      "\n",
      " Are there groups of cereals w similar fatcaloriessugar\n",
      " Is there a cluster of typical film lengths\n",
      "\n",
      "\n",
      "\n",
      "10\n",
      "\n",
      "Correlate\n",
      "\n",
      "Given a set of data cases and two attributes determine useful relationships between the values of those attributes\n",
      "\n",
      "What is the correlation between attributes X and Y over a given set S of data cases\n",
      "\n",
      " Is there a correlation between carbohydrates and fat\n",
      " Is there a correlation between country of origin and MPG\n",
      " Do different genders have a preferred payment method\n",
      " Is there a trend of increasing film length over the years\n",
      "\n",
      "\n",
      "\n",
      "11\n",
      "\n",
      " Contextualization911793\n",
      "\n",
      "Given a set of data cases find contextual relevancy of the data to the users\n",
      "\n",
      "Which data cases in a set S of data cases are relevant to the current users context\n",
      "\n",
      " Are there groups of restaurants that have foods based on my current caloric intake\n",
      "\n",
      "\n",
      "Barriers to effective analysisedit\n",
      "Barriers to effective analysis may exist among the analysts performing the data analysis or among the audience Distinguishing fact from opinion cognitive biases and innumeracy are all challenges to sound data analysis\n",
      "\n",
      "Confusing fact and opinionedit\n",
      "mwparseroutput quoteboxbackgroundcolorF9F9F9border1px solid aaaboxsizingborderboxpadding10pxfontsize88mwparseroutput quoteboxfloatleftmargin05em 14em 08em 0mwparseroutput quoteboxfloatrightmargin05em 0 08em 14emmwparseroutput quoteboxcenteredmargin05em auto 08em automwparseroutput quoteboxfloatleft pmwparseroutput quoteboxfloatright pfontstyleinheritmwparseroutput quoteboxtitlebackgroundcolorF9F9F9textaligncenterfontsizelargerfontweightboldmwparseroutput quoteboxquotequotedbeforefontfamilyTimes New Romanseriffontweightboldfontsizelargecolorgraycontent “ verticalalign45lineheight0mwparseroutput quoteboxquotequotedafterfontfamilyTimes New Romanseriffontweightboldfontsizelargecolorgraycontent ” lineheight0mwparseroutput quotebox leftalignedtextalignleftmwparseroutput quotebox rightalignedtextalignrightmwparseroutput quotebox centeralignedtextaligncentermwparseroutput quotebox citedisplayblockfontstylenormalmedia screen and maxwidth360pxmwparseroutput quoteboxminwidth100margin0 0 08emimportantfloatnoneimportant\n",
      "You are entitled to your own opinion but you are not entitled to your own facts\n",
      "Daniel Patrick Moynihan\n",
      "\n",
      "\n",
      "Effective analysis requires obtaining relevant facts to answer questions support a conclusion or formal opinion or test hypotheses Facts by definition are irrefutable meaning that any person involved in the analysis should be able to agree upon them For example in August 2010 the Congressional Budget Office CBO estimated that extending the Bush tax cuts of 2001 and 2003 for the 2011–2020 time period would add approximately 33 trillion to the national debt911893 Everyone should be able to agree that indeed this is what CBO reported they can all examine the report This makes it a fact Whether persons agree or disagree with the CBO is their own opinion\n",
      "As another example the auditor of a public company must arrive at a formal opinion on whether financial statements of publicly traded corporations are fairly stated in all material respects This requires extensive analysis of factual data and evidence to support their opinion When making the leap from facts to opinions there is always the possibility that the opinion is erroneous\n",
      "\n",
      "Cognitive biasesedit\n",
      "There are a variety of cognitive biases that can adversely affect analysis For example confirmation bias is the tendency to search for or interpret information in a way that confirms ones preconceptions In addition individuals may discredit information that does not support their views\n",
      "Analysts may be trained specifically to be aware of these biases and how to overcome them In his book Psychology of Intelligence Analysis retired CIA analyst Richards Heuer wrote that analysts should clearly delineate their assumptions and chains of inference and specify the degree and source of the uncertainty involved in the conclusions He emphasized procedures to help surface and debate alternative points of view911993\n",
      "\n",
      "Innumeracyedit\n",
      "Effective analysts are generally adept with a variety of numerical techniques However audiences may not have such literacy with numbers or numeracy they are said to be innumerate  Persons communicating the data may also be attempting to mislead or misinform deliberately using bad numerical techniques912093\n",
      "For example whether a number is rising or falling may not be the key factor More important may be the number relative to another number such as the size of government revenue or spending relative to the size of the economy GDP or the amount of cost relative to revenue in corporate financial statements This numerical technique is referred to as normalization91793 or commonsizing There are many such techniques employed by analysts whether adjusting for inflation ie comparing real vs nominal data or considering population increases demographics etc Analysts apply a variety of techniques to address the various quantitative messages described in the section above\n",
      "Analysts may also analyze data under different assumptions or scenarios For example when analysts perform financial statement analysis they will often recast the financial statements under different assumptions to help arrive at an estimate of future cash flow which they then discount to present value based on some interest rate to determine the valuation of the company or its stock  Similarly the CBO analyzes the effects of various policy options on the governments revenue outlays and deficits creating alternative future scenarios for key measures\n",
      "\n",
      "Other topicsedit\n",
      "Smart buildingsedit\n",
      "A data analytics approach can be used in order to predict energy consumption in buildings912193 The different steps of the data analysis process are carried out in order to realise smart buildings where the building management and control operations including heating ventilation air conditioning lighting and security are realised automatically by miming the needs of the building users and optimising resources like energy and time\n",
      "\n",
      "Analytics and business intelligenceedit\n",
      "Main article Analytics\n",
      "Analytics is the extensive use of data statistical and quantitative analysis explanatory and predictive models and factbased management to drive decisions and actions It is a subset of business intelligence which is a set of technologies and processes that use data to understand and analyze business performance912293\n",
      "\n",
      "Educationedit\n",
      "  Analytic activities of data visualization users\n",
      "In education most educators have access to a data system for the purpose of analyzing student data912393 These data systems present data to educators in an overthecounter data format embedding labels supplemental documentation and a help system and making key packagedisplay and content decisions to improve the accuracy of educators’ data analyses912493\n",
      "\n",
      "Practitioner notesedit\n",
      "This section contains rather technical explanations that may assist practitioners but are beyond the typical scope of a Wikipedia article\n",
      "\n",
      "Initial data analysisedit\n",
      "The most important distinction between the initial data analysis phase and the main analysis phase is that during initial data analysis one refrains from any analysis that is aimed at answering the original research question The initial data analysis phase is guided by the following four questions912593\n",
      "\n",
      "Quality of dataedit\n",
      "The quality of the data should be checked as early as possible Data quality can be assessed in several ways using different types of analysis frequency counts descriptive statistics mean standard deviation median normality skewness kurtosis frequency histograms n variables are compared with coding schemes of variables external to the data set and possibly corrected if coding schemes are not comparable\n",
      "\n",
      "Test for commonmethod variance\n",
      "The choice of analyses to assess the data quality during the initial data analysis phase depends on the analyses that will be conducted in the main analysis phase912693\n",
      "\n",
      "Quality of measurementsedit\n",
      "The quality of the measurement instruments should only be checked during the initial data analysis phase when this is not the focus or research question of the study One should check whether structure of measurement instruments corresponds to structure reported in the literature\n",
      "There are two ways to assess measurement NOTE only one way seems to be listed\n",
      "\n",
      "Analysis of homogeneity internal consistency which gives an indication of the reliability of a measurement instrument During this analysis one inspects the variances of the items and the scales the Cronbachs α of the scales and the change in the Cronbachs alpha when an item would be deleted from a scale912793\n",
      "Initial transformationsedit\n",
      "After assessing the quality of the data and of the measurements one might decide to impute missing data or to perform initial transformations of one or more variables although this can also be done during the main analysis phase912893\n",
      "Possible transformations of variables are912993\n",
      "\n",
      "Square root transformation if the distribution differs moderately from normal\n",
      "Logtransformation if the distribution differs substantially from normal\n",
      "Inverse transformation if the distribution differs severely from normal\n",
      "Make categorical ordinal  dichotomous if the distribution differs severely from normal and no transformations help\n",
      "Did the implementation of the study fulfill the intentions of the research designedit\n",
      "One should check the success of the randomization procedure for instance by checking whether background and substantive variables are equally distributed within and across groups \n",
      "If the study did not need or use a randomization procedure one should check the success of the nonrandom sampling for instance by checking whether all subgroups of the population of interest are represented in sample\n",
      "Other possible data distortions that should be checked are\n",
      "\n",
      "dropout this should be identified during the initial data analysis phase\n",
      "Item nonresponse whether this is random or not should be assessed during the initial data analysis phase\n",
      "Treatment quality using manipulation checks913093\n",
      "Characteristics of data sampleedit\n",
      "In any report or article the structure of the sample must be accurately described It is especially important to exactly determine the structure of the sample and specifically the size of the subgroups when subgroup analyses will be performed during the main analysis phase\n",
      "The characteristics of the data sample can be assessed by looking at\n",
      "\n",
      "Basic statistics of important variables\n",
      "Scatter plots\n",
      "Correlations and associations\n",
      "Crosstabulations913193\n",
      "Final stage of the initial data analysisedit\n",
      "During the final stage the findings of the initial data analysis are documented and necessary preferable and possible corrective actions are taken\n",
      "Also the original plan for the main data analyses can and should be specified in more detail or rewritten In order to do this several decisions about the main data analyses can and should be made\n",
      "\n",
      "In the case of nonnormals should one transform variables make variables categorical ordinaldichotomous adapt the analysis method\n",
      "In the case of missing data should one neglect or impute the missing data which imputation technique should be used\n",
      "In the case of outliers should one use robust analysis techniques\n",
      "In case items do not fit the scale should one adapt the measurement instrument by omitting items or rather ensure comparability with other uses of the measurement instruments\n",
      "In the case of too small subgroups should one drop the hypothesis about intergroup differences or use small sample techniques like exact tests or bootstrapping\n",
      "In case the randomization procedure seems to be defective can and should one calculate propensity scores and include them as covariates in the main analyses913293\n",
      "Analysisedit\n",
      "Several analyses can be used during the initial data analysis phase913393\n",
      "\n",
      "Univariate statistics single variable\n",
      "Bivariate associations correlations\n",
      "Graphical techniques scatter plots\n",
      "It is important to take the measurement levels of the variables into account for the analyses as special statistical techniques are available for each level913493\n",
      "\n",
      "Nominal and ordinal variables\n",
      "Frequency counts numbers and percentages\n",
      "Associations\n",
      "circumambulations crosstabulations\n",
      "hierarchical loglinear analysis restricted to a maximum of 8 variables\n",
      "loglinear analysis to identify relevantimportant variables and possible confounders\n",
      "Exact tests or bootstrapping in case subgroups are small\n",
      "Computation of new variables\n",
      "Continuous variables\n",
      "Distribution\n",
      "Statistics M SD variance skewness kurtosis\n",
      "Stemandleaf displays\n",
      "Box plots\n",
      "Nonlinear analysisedit\n",
      "Nonlinear analysis will be necessary when the data is recorded from a nonlinear system Nonlinear systems can exhibit complex dynamic effects including bifurcations chaos harmonics and subharmonics that cannot be analyzed using simple linear methods  Nonlinear data analysis is closely related to nonlinear system identification913593\n",
      "\n",
      "Main data analysisedit\n",
      "In the main analysis phase analyses aimed at answering the research question are performed as well as any other relevant analysis needed to write the first draft of the research report913693\n",
      "\n",
      "Exploratory and confirmatory approachesedit\n",
      "In the main analysis phase either an exploratory or confirmatory approach can be adopted Usually the approach is decided before data is collected In an exploratory analysis no clear hypothesis is stated before analysing the data and the data is searched for models that describe the data well In a confirmatory analysis clear hypotheses about the data are tested\n",
      "Exploratory data analysis should be interpreted carefully When testing multiple models at once there is a high chance on finding at least one of them to be significant but this can be due to a type 1 error It is important to always adjust the significance level when testing multiple models with for example a Bonferroni correction Also one should not follow up an exploratory analysis with a confirmatory analysis in the same dataset An exploratory analysis is used to find ideas for a theory but not to test that theory as well When a model is found exploratory in a dataset then following up that analysis with a confirmatory analysis in the same dataset could simply mean that the results of the confirmatory analysis are due to the same type 1 error that resulted in the exploratory model in the first place The confirmatory analysis therefore will not be more informative than the original exploratory analysis913793\n",
      "\n",
      "Stability of resultsedit\n",
      "It is important to obtain some indication about how generalizable the results are913893 While this is hard to check one can look at the stability of the results Are the results reliable and reproducible There are two main ways of doing this\n",
      "\n",
      "Crossvalidation By splitting the data in multiple parts we can check if an analysis like a fitted model based on one part of the data generalizes to another part of the data as well\n",
      "Sensitivity analysis A procedure to study the behavior of a system or model when global parameters are systematically varied One way to do this is with bootstrapping\n",
      "Statistical methodsedit\n",
      "Many statistical methods have been used for statistical analyses A very brief list of four of the more popular methods is\n",
      "\n",
      "General linear model A widely used model on which various methods are based eg t test ANOVA ANCOVA MANOVA Usable for assessing the effect of several predictors on one or more continuous dependent variables\n",
      "Generalized linear model An extension of the general linear model for discrete dependent variables\n",
      "Structural equation modelling Usable for assessing latent structures from measured manifest variables\n",
      "Item response theory Models for mostly assessing one latent variable from several binary measured variables eg an exam\n",
      "Free software for data analysisedit\n",
      "DevInfo – a database system endorsed by the United Nations Development Group for monitoring and analyzing human development\n",
      "ELKI – data mining framework in Java with data mining oriented visualization functions\n",
      "KNIME – the Konstanz Information Miner a user friendly and comprehensive data analytics framework\n",
      "Orange – A visual programming tool featuring interactive data visualization and methods for statistical data analysis data mining and machine learning\n",
      "PAST – free software for scientific data analysis\n",
      "PAW – FORTRANC data analysis framework developed at CERN\n",
      "R – a programming language and software environment for statistical computing and graphics\n",
      "ROOT –  C++ data analysis framework developed at CERN\n",
      "SciPy and Pandas – Python libraries for data analysis\n",
      "International data analysis contestsedit\n",
      "Different companies or organizations hold a data analysis contests to encourage researchers utilize their data or to solve a particular question using data analysis A few examples of wellknown international data analysis contests are as follows \n",
      "\n",
      "Kaggle competition held by Kaggle913993\n",
      "LTPP data analysis contest held by FHWA and ASCE914093914193\n",
      "See alsoedit\n",
      "\n",
      "\n",
      "statistics portal\n",
      "\n",
      "Actuarial science\n",
      "Analytics\n",
      "Big data\n",
      "Business intelligence\n",
      "Censoring statistics\n",
      "Computational physics\n",
      "Data acquisition\n",
      "Data blending\n",
      "Data governance\n",
      "Data mining\n",
      "Data Presentation Architecture\n",
      "Data science\n",
      "Digital signal processing\n",
      "Dimension reduction\n",
      "Early case assessment\n",
      "Exploratory data analysis\n",
      "Fourier analysis\n",
      "Machine learning\n",
      "Multilinear PCA\n",
      "Multilinear subspace learning\n",
      "Multiway data analysis\n",
      "Nearest neighbor search\n",
      "Nonlinear system identification\n",
      "Predictive analytics\n",
      "Principal component analysis\n",
      "Qualitative research\n",
      "Scientific computing\n",
      "Structured data analysis statistics\n",
      "System identification\n",
      "Test method\n",
      "Text analytics\n",
      "Unstructured data\n",
      "Wavelet\n",
      "\n",
      "Referencesedit\n",
      "Citationsedit\n",
      "\n",
      "\n",
      " Exploring Data Analysis\n",
      "\n",
      " a b c Judd Charles and McCleland Gary 1989 Data Analysis Harcourt Brace Jovanovich ISBN1600155167650mwparseroutput citecitationfontstyleinheritmwparseroutput qquotesmwparseroutput codecs1codecolorinheritbackgroundinheritborderinheritpaddinginheritmwparseroutput cs1lockfree abackgroundurluploadwikimediaorgwikipediacommonsthumb665Lockgreensvg9pxLockgreensvgpngnorepeatbackgroundpositionright 1em centermwparseroutput cs1locklimited amwparseroutput cs1lockregistration abackgroundurluploadwikimediaorgwikipediacommonsthumbdd6Lockgrayalt2svg9pxLockgrayalt2svgpngnorepeatbackgroundpositionright 1em centermwparseroutput cs1locksubscription abackgroundurluploadwikimediaorgwikipediacommonsthumbaaaLockredalt2svg9pxLockredalt2svgpngnorepeatbackgroundpositionright 1em centermwparseroutput cs1subscriptionmwparseroutput cs1registrationcolor555mwparseroutput cs1subscription spanmwparseroutput cs1registration spanborderbottom1px dottedcursorhelpmwparseroutput cs1hiddenerrordisplaynonefontsize100mwparseroutput cs1visibleerrorfontsize100mwparseroutput cs1subscriptionmwparseroutput cs1registrationmwparseroutput cs1formatfontsize95mwparseroutput cs1kernleftmwparseroutput cs1kernwlleftpaddingleft02emmwparseroutput cs1kernrightmwparseroutput cs1kernwlrightpaddingright02em\n",
      "\n",
      " John TukeyThe Future of Data AnalysisJuly 1961\n",
      "\n",
      " a b c d e f g ONeil Cathy and Schutt Rachel 2013 Doing Data Science OReilly ISBN1609781449358655\n",
      "\n",
      " Clean Data in CRM The Key to Generate SalesReady Leads and Boost Your Revenue Pool Retrieved 29th July 2016\n",
      "\n",
      " Data Cleaning Microsoft Research Retrieved 26 October 2013\n",
      "\n",
      " a b c Perceptual EdgeJonathan KoomeyBest practices for understanding quantitative dataFebruary 14 2006\n",
      "\n",
      " Hellerstein Joseph 27 February 2008 Quantitative Data Cleaning for Large Databases PDF EECS Computer Science Division 3 Retrieved 26 October 2013\n",
      "\n",
      " Stephen FewPerceptual EdgeSelecting the Right Graph For Your MessageSeptember 2004\n",
      "\n",
      " BehrensPrinciples and Procedures of Exploratory Data AnalysisAmerican Psychological Association1997\n",
      "\n",
      " Grandjean Martin 2014 La connaissance est un réseau PDF Les Cahiers du Numérique 10 3 37–54 doi103166lcn1033754\n",
      "\n",
      " Stephen FewPerceptual EdgeSelecting the Right Graph for Your Message2004\n",
      "\n",
      " Stephen FewPerceptual EdgeGraph Selection Matrix\n",
      "\n",
      " Robert Amar James Eagan and John Stasko 2005 LowLevel Components of Analytic Activity in Information Visualization\n",
      "\n",
      " William Newman 1994 A Preliminary Analysis of the Products of HCI Research Using Pro Forma Abstracts\n",
      "\n",
      " Mary Shaw 2002 What Makes Good Research in Software Engineering\n",
      "\n",
      " a b ConTaaS An Approach to InternetScale Contextualisation for Developing Efficient Internet of Things Applications ScholarSpace HICSS50 Retrieved May 24 2017\n",
      "\n",
      " Congressional Budget OfficeThe Budget and Economic OutlookAugust 2010Table 17 on Page 24 PDF Retrieved 20110331\n",
      "\n",
      " Introduction ciagov\n",
      "\n",
      " BloombergBarry RitholzBad Math that Passes for InsightOctober 28 2014\n",
      "\n",
      " GonzálezVidal Aurora MorenoCano Victoria 2016 Towards energy efficiency smart buildings models based on intelligent data analytics Procedia Computer Science 83 Elsevier 994–999 doi101016jprocs201604213\n",
      "\n",
      " Davenport Thomas and Harris Jeanne 2007 Competing on Analytics OReilly ISBN1609781422103326\n",
      "\n",
      " Aarons D 2009 Report finds states on course to build pupildata systems Education Week 2913 6\n",
      "\n",
      " Rankin J 2013 March 28 How data Systems amp reports can either fight or propagate the data analysis error epidemic and how educator leaders can help Presentation conducted from Technology Information Center for Administrative Leadership TICAL School Leadership Summit\n",
      "\n",
      " Adèr 2008a p160337\n",
      "\n",
      " Adèr 2008a pp160338341\n",
      "\n",
      " Adèr 2008a pp160341342\n",
      "\n",
      " Adèr 2008a p160344\n",
      "\n",
      " Tabachnick amp Fidell 2007 p 8788\n",
      "\n",
      " Adèr 2008a pp160344345\n",
      "\n",
      " Adèr 2008a p160345\n",
      "\n",
      " Adèr 2008a pp160345346\n",
      "\n",
      " Adèr 2008a pp160346347\n",
      "\n",
      " Adèr 2008a pp160349353\n",
      "\n",
      " Billings SA Nonlinear System Identification NARMAX Methods in the Time Frequency and SpatioTemporal Domains Wiley 2013\n",
      "\n",
      " Adèr 2008b p160363\n",
      "\n",
      " Adèr 2008b pp160361362\n",
      "\n",
      " Adèr 2008b pp160361371\n",
      "\n",
      " The machine learning community takes on the Higgs Symmetry Magazine July 15 2014 Retrieved 14 January 2015\n",
      "\n",
      " Nehme Jean September 29 2016 LTPP International Data Analysis Contest Federal Highway Administration Retrieved October 22 2017\n",
      "\n",
      " DataGovLongTerm Pavement Performance LTPP May 26 2016 Retrieved November 10 2017\n",
      "\n",
      "\n",
      "Bibliographyedit\n",
      "Adèr Herman J 2008a Chapter 14 Phases and initial steps in data analysis  In Adèr Herman J Mellenbergh Gideon J Hand David J Advising on research methods160 a consultants companion Huizen Netherlands Johannes van Kessel Pub pp160333–356 ISBN1609789079418015 OCLC160905799857\n",
      "Adèr Herman J 2008b Chapter 15 The main analysis phase  In Adèr Herman J Mellenbergh Gideon J Hand David J Advising on research methods160 a consultants companion Huizen Netherlands Johannes van Kessel Pub pp160357–386 ISBN1609789079418015 OCLC160905799857\n",
      "Tabachnick BG amp Fidell LS 2007 Chapter 4 Cleaning up your act Screening data prior to analysis In BG Tabachnick amp LS Fidell Eds Using Multivariate Statistics Fifth Edition pp16060–116 Boston Pearson Education Inc  Allyn and Bacon\n",
      "Further readingedit\n",
      "\n",
      "\n",
      "\n",
      "Wikiversity has learning resources about Data analysis\n",
      "Adèr HJ amp Mellenbergh GJ with contributions by DJ Hand 2008 Advising on Research Methods A Consultants Companion Huizen the Netherlands Johannes van Kessel Publishing\n",
      "Chambers John M Cleveland William S Kleiner Beat Tukey Paul A 1983 Graphical Methods for Data Analysis WadsworthDuxbury Press ISBN160053498052X\n",
      "Fandango Armando 2008 Python Data Analysis 2nd Edition Packt Publishers\n",
      "Juran Joseph M Godfrey A Blanton 1999 Jurans Quality Handbook 5th Edition New York McGraw Hill ISBN160007034003X\n",
      "LewisBeck Michael S 1995 Data Analysis an Introduction Sage Publications Inc ISBN1600803957726\n",
      "NISTSEMATECH 2008 Handbook of Statistical Methods\n",
      "Pyzdek T 2003 Quality Engineering Handbook ISBN1600824746147\n",
      "Richard Veryard 1984 Pragmatic Data Analysis Oxford160 Blackwell Scientific Publications ISBN1600632013117\n",
      "Tabachnick BG Fidell LS 2007 Using Multivariate Statistics 5th Edition Boston Pearson Education Inc  Allyn and Bacon ISBN1609780205459384\n",
      "Authority control \n",
      "GND 41230371\n",
      "\n",
      "vteData\n",
      "Analysis\n",
      "Archaeology\n",
      "Cleansing\n",
      "Collection\n",
      "Compression\n",
      "Corruption\n",
      "Curation\n",
      "Degradation\n",
      "Editing\n",
      "Farming\n",
      "Format management\n",
      "Fusion\n",
      "Integration\n",
      "Integrity\n",
      "Library\n",
      "Loss\n",
      "Management\n",
      "Migration\n",
      "Mining\n",
      "Preprocessing\n",
      "Preservation\n",
      "Protection privacy\n",
      "Recovery\n",
      "Reduction\n",
      "Retention\n",
      "Quality\n",
      "Science\n",
      "Scraping\n",
      "Scrubbing\n",
      "Security\n",
      "Stewardship\n",
      "Storage\n",
      "Validation\n",
      "Warehouse\n",
      "Wranglingmunging\n",
      "\n",
      "\n",
      " \n",
      "NewPP limit report\n",
      "Parsed by mw1258\n",
      "Cached time 20181023205919\n",
      "Cache expiry 1900800\n",
      "Dynamic content false\n",
      "CPU time usage 0596 seconds\n",
      "Real time usage 0744 seconds\n",
      "Preprocessor visited node count 31771000000\n",
      "Preprocessor generated node count 01500000\n",
      "Post‐expand include size 729952097152 bytes\n",
      "Template argument size 28332097152 bytes\n",
      "Highest expansion depth 1240\n",
      "Expensive parser function count 5500\n",
      "Unstrip recursion depth 120\n",
      "Unstrip post‐expand size 621355000000 bytes\n",
      "Number of Wikibase entities loaded 3400\n",
      "Lua time usage 023010000 seconds\n",
      "Lua memory usage 576 MB50 MB\n",
      "\n",
      "\n",
      "Transclusion expansion time report mscallstemplate\n",
      "10000  523114      1 total\n",
      " 3198  167305      1 TemplateReflist\n",
      " 1744   91248      5 TemplateCitebook\n",
      "  971   50806      6 TemplateISBN\n",
      "  763   39937      1 TemplateAccordingtowhom\n",
      "  734   38394      3 TemplateCitejournal\n",
      "  698   36524      1 TemplateAuthoritycontrol\n",
      "  673   35217      2 TemplateSidebarwithcollapsiblelists\n",
      "  658   34408      1 TemplateFixspan\n",
      "  582   30459      1 TemplateDataVisualization\n",
      "\n",
      "\n",
      " Saved in parser cache with key enwikipcacheidhash27209540canonical and timestamp 20181023205918 and revision id 862584710\n",
      " \n",
      "\t\t\t\t\t\n",
      "\t\t\t\t\t\tRetrieved from httpsenwikipediaorgwindexphptitle=Dataanalysisampoldid=862584710\t\t\t\t\t\n",
      "\t\t\t\tCategories Data analysisScientific methodParticle physicsComputational fields of studyHidden categories All articles with specifically marked weaselworded phrasesArticles with specifically marked weaselworded phrases from March 2018Wikipedia articles needing clarification from March 2018Wikipedia articles with GND identifiers\t\t\t\t\n",
      "\t\t\t\t\t\t\t\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t\tNavigation menu\n",
      "\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\tPersonal tools\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\tNot logged inTalkContributionsCreate accountLog in\t\t\t\t\t\t\n",
      "\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\tNamespaces\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\tArticleTalk\t\t\t\t\t\t\n",
      "\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\tVariants\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\tViews\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\tReadEditView history\t\t\t\t\t\t\n",
      "\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\tMore\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\tSearch\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\t\t\n",
      "\t\t\tNavigation\n",
      "\t\t\t\n",
      "\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\tMain pageContentsFeatured contentCurrent eventsRandom articleDonate to WikipediaWikipedia store\t\t\t\t\n",
      "\t\t\t\t\t\t\t\n",
      "\t\t\n",
      "\t\t\t\n",
      "\t\t\tInteraction\n",
      "\t\t\t\n",
      "\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\tHelpAbout WikipediaCommunity portalRecent changesContact page\t\t\t\t\n",
      "\t\t\t\t\t\t\t\n",
      "\t\t\n",
      "\t\t\t\n",
      "\t\t\tTools\n",
      "\t\t\t\n",
      "\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\tWhat links hereRelated changesUpload fileSpecial pagesPermanent linkPage informationWikidata itemCite this page\t\t\t\t\n",
      "\t\t\t\t\t\t\t\n",
      "\t\t\n",
      "\t\t\t\n",
      "\t\t\tPrintexport\n",
      "\t\t\t\n",
      "\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\tCreate a bookDownload as PDFPrintable version\t\t\t\t\n",
      "\t\t\t\t\t\t\t\n",
      "\t\t\n",
      "\t\t\t\n",
      "\t\t\tIn other projects\n",
      "\t\t\t\n",
      "\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\tWikimedia Commons\t\t\t\t\n",
      "\t\t\t\t\t\t\t\n",
      "\t\t\n",
      "\t\t\t\n",
      "\t\t\tLanguages\n",
      "\t\t\t\n",
      "\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\tالعربيةDeutschEestiEspañolEsperantoفارسیFrançaisहिन्दीItalianoעבריתಕನ್ನಡMagyarPolskiPortuguêsРусскийසිංහලکوردیSuomiதமிழ்Українська中文\t\t\t\t\n",
      "\t\t\t\tEdit links\t\t\t\n",
      "\t\t\n",
      "\t\t\t\t\n",
      "\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t This page was last edited on 5 October 2018 at 0950 UTC\n",
      "\t\t\t\t\t\t\t\tText is available under the Creative Commons AttributionShareAlike License\n",
      "additional terms may apply  By using this site you agree to the Terms of Use and Privacy Policy Wikipedia® is a registered trademark of the Wikimedia Foundation Inc a nonprofit organization\n",
      "\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\tPrivacy policy\n",
      "\t\t\t\t\t\t\t\tAbout Wikipedia\n",
      "\t\t\t\t\t\t\t\tDisclaimers\n",
      "\t\t\t\t\t\t\t\tContact Wikipedia\n",
      "\t\t\t\t\t\t\t\tDevelopers\n",
      "\t\t\t\t\t\t\t\tCookie statement\n",
      "\t\t\t\t\t\t\t\tMobile view\n",
      "\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Lorem Ipsum  All the facts  Lipsum generator\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "googletagcmdpushfunction  googletagdisplaydivgptad14561483161980 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1344137713971381140813811398 Shqip 82351575160415931585157616101577nbspnbsp 104110981083107510721088108910821080 Catalagrave 20013259913161620307 Hrvatski 268esky Dansk Nederlands English Eesti Filipino Suomi Franccedilais 4325430443204311432343144312 Deutsch 917955955951957953954940 823515061489151214971514nbspnbsp 236123672344238123422368 Magyar Indonesia Italiano Latviski Lietuviscaronkai 1084107210821077107610861085108910821080 Melayu Norsk Polski Portuguecircs Romacircna Pycc108210801081 105710881087108910821080 Sloven269ina Sloven353269ina Espantildeol Svenska 365236073618 Tuumlrkccedile 1059108210881072111110851089110010821072 Ti7871ng Vi7879t \n",
      "\n",
      "Lorem Ipsum\n",
      "Neque porro quisquam est qui dolorem ipsum quia dolor sit amet consectetur adipisci velit\n",
      "There is no one who loves pain itself who seeks after it and wants to have it simply because it is pain\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "What is Lorem Ipsum\n",
      "Lorem Ipsum is simply dummy text of the printing and typesetting industry Lorem Ipsum has been the industrys standard dummy text ever since the 1500s when an unknown printer took a galley of type and scrambled it to make a type specimen book It has survived not only five centuries but also the leap into electronic typesetting remaining essentially unchanged It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum\n",
      "\n",
      "Why do we use it\n",
      "It is a long established fact that a reader will be distracted by the readable content of a page when looking at its layout The point of using Lorem Ipsum is that it has a moreorless normal distribution of letters as opposed to using Content here content here making it look like readable English Many desktop publishing packages and web page editors now use Lorem Ipsum as their default model text and a search for lorem ipsum will uncover many web sites still in their infancy Various versions have evolved over the years sometimes by accident sometimes on purpose injected humour and the like\n",
      "\n",
      "Where does it come from\n",
      "Contrary to popular belief Lorem Ipsum is not simply random text It has roots in a piece of classical Latin literature from 45 BC making it over 2000 years old Richard McClintock a Latin professor at HampdenSydney College in Virginia looked up one of the more obscure Latin words consectetur from a Lorem Ipsum passage and going through the cites of the word in classical literature discovered the undoubtable source Lorem Ipsum comes from sections 11032 and 11033 of de Finibus Bonorum et Malorum The Extremes of Good and Evil by Cicero written in 45 BC This book is a treatise on the theory of ethics very popular during the Renaissance The first line of Lorem Ipsum Lorem ipsum dolor sit amet comes from a line in section 11032The standard chunk of Lorem Ipsum used since the 1500s is reproduced below for those interested Sections 11032 and 11033 from de Finibus Bonorum et Malorum by Cicero are also reproduced in their exact original form accompanied by English versions from the 1914 translation by H Rackham\n",
      "\n",
      "Where can I get some\n",
      "There are many variations of passages of Lorem Ipsum available but the majority have suffered alteration in some form by injected humour or randomised words which dont look even slightly believable If you are going to use a passage of Lorem Ipsum you need to be sure there isnt anything embarrassing hidden in the middle of text All the Lorem Ipsum generators on the Internet tend to repeat predefined chunks as necessary making this the first true generator on the Internet It uses a dictionary of over 200 Latin words combined with a handful of model sentence structures to generate Lorem Ipsum which looks reasonable The generated Lorem Ipsum is therefore always free from repetition injected humour or noncharacteristic words etc\n",
      "paragraphswordsbyteslistsStart with Loremipsum dolor sit amet\n",
      "Translations Can you help translate this site into a foreign language  Please email us with details if you can help\n",
      "\n",
      "There are now a set of mock banners available here in three colours and in a range of standard banner sizes\n",
      "\n",
      "Donate If you use this site regularly and would like to help keep the site on the Internet please consider donating a small sum to help pay for the hosting and bandwidth bill There is no minimum donation any sum is appreciated  click here to donate using PayPal Thank you for your support\n",
      "\n",
      "\n",
      "Chrome\n",
      "Firefox Addon\n",
      "NodeJS\n",
      "TeX Package\n",
      "Python Interface\n",
      "GTK Lipsum\n",
      "Rails\n",
      "NET\n",
      "Groovy\n",
      "Adobe Plugin\n",
      "\n",
      "\n",
      "\n",
      "The standard Lorem Ipsum passage used since the 1500sLorem ipsum dolor sit amet consectetur adipiscing elit sed do eiusmod tempor incididunt ut labore et dolore magna aliqua Ut enim ad minim veniam quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur Excepteur sint occaecat cupidatat non proident sunt in culpa qui officia deserunt mollit anim id est laborumSection 11032 of de Finibus Bonorum et Malorum written by Cicero in 45 BCSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium totam rem aperiam eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt Neque porro quisquam est qui dolorem ipsum quia dolor sit amet consectetur adipisci velit sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam quaerat voluptatem Ut enim ad minima veniam quis nostrum exercitationem ullam corporis suscipit laboriosam nisi ut aliquid ex ea commodi consequatur Quis autem vel eum iure reprehenderit qui in ea voluptate velit esse quam nihil molestiae consequatur vel illum qui dolorem eum fugiat quo voluptas nulla pariatur\n",
      "1914 translation by H Rackham\n",
      "But I must explain to you how all this mistaken idea of denouncing pleasure and praising pain was born and I will give you a complete account of the system and expound the actual teachings of the great explorer of the truth the masterbuilder of human happiness No one rejects dislikes or avoids pleasure itself because it is pleasure but because those who do not know how to pursue pleasure rationally encounter consequences that are extremely painful Nor again is there anyone who loves or pursues or desires to obtain pain of itself because it is pain but because occasionally circumstances occur in which toil and pain can procure him some great pleasure To take a trivial example which of us ever undertakes laborious physical exercise except to obtain some advantage from it But who has any right to find fault with a man who chooses to enjoy a pleasure that has no annoying consequences or one who avoids a pain that produces no resultant pleasure\n",
      "Section 11033 of de Finibus Bonorum et Malorum written by Cicero in 45 BC\n",
      "At vero eos et accusamus et iusto odio dignissimos ducimus qui blanditiis praesentium voluptatum deleniti atque corrupti quos dolores et quas molestias excepturi sint occaecati cupiditate non provident similique sunt in culpa qui officia deserunt mollitia animi id est laborum et dolorum fuga Et harum quidem rerum facilis est et expedita distinctio Nam libero tempore cum soluta nobis est eligendi optio cumque nihil impedit quo minus id quod maxime placeat facere possimus omnis voluptas assumenda est omnis dolor repellendus Temporibus autem quibusdam et aut officiis debitis aut rerum necessitatibus saepe eveniet ut et voluptates repudiandae sint et molestiae non recusandae Itaque earum rerum hic tenetur a sapiente delectus ut aut reiciendis voluptatibus maiores alias consequatur aut perferendis doloribus asperiores repellat\n",
      "1914 translation by H Rackham\n",
      "On the other hand we denounce with righteous indignation and dislike men who are so beguiled and demoralized by the charms of pleasure of the moment so blinded by desire that they cannot foresee the pain and trouble that are bound to ensue and equal blame belongs to those who fail in their duty through weakness of will which is the same as saying through shrinking from toil and pain These cases are perfectly simple and easy to distinguish In a free hour when our power of choice is untrammelled and when nothing prevents our being able to do what we like best every pleasure is to be welcomed and every pain avoided But in certain circumstances and owing to the claims of duty or the obligations of business it will frequently occur that pleasures have to be repudiated and annoyances accepted The wise man therefore always holds in these matters to this principle of selection he rejects pleasures to secure other greater pleasures or else he endures pains to avoid worse pains\n",
      "\n",
      "\n",
      "\n",
      "googletagcmdpushfunction  googletagdisplaydivgptad14745377621222 \n",
      "\n",
      "\n",
      "googletagcmdpushfunction  googletagdisplaydivgptad14745377621223 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "104101108112641081051121151171094699111109Privacy Policy\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "googletagcmdpushfunction  googletagdisplaydivgptad14561483161981 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'bag_of_words': [], 'term_freq': []}\n"
     ]
    }
   ],
   "source": [
    "bow = get_bow_from_docs([\n",
    "        'www.coursereport.com_ironhack.html',\n",
    "        'en.wikipedia.org_Data_analysis.html',\n",
    "        'www.lipsum.com.html'\n",
    "    ],\n",
    "    stop_words.ENGLISH_STOP_WORDS\n",
    ")\n",
    "\n",
    "print(bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see any problem in the output? How do you improve the output?\n",
    "\n",
    "A good way to improve your codes is to look into the HTML data sources and try to understand where the messy output came from. A good data analyst always learns about the data in depth in order to perform the job well.\n",
    "\n",
    "Spend 20-30 minutes to improve your functions or until you feel you are good at string operations. This lab is just a practice so you don't need to stress yourself out. If you feel you've practiced enough you can stop and move on the next challenge question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
